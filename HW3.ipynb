{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a069221c-b6aa-44d5-a33e-e43e554079fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import bs4 as bs\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63d93aa8-13cf-4c9d-9d17-0eb2d45f097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://www.atlasobscura.com/places?page=202&sort=likes_count\"\n",
    "raw = rq.get(url)\n",
    "soup = bs.BeautifulSoup(raw.content)\n",
    "\n",
    "#ciao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e9198d1-6b21-4f04-8b3d-f73ef280b8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f858e4e-060e-4ffd-8f99-049417819ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all(\"a\",attrs={'data-place-id':re.compile(r\"\\d*\")}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a26b00-8c57-4415-a748-e06c0c97275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_url = []\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "for page in range(1,401):\n",
    "    try:\n",
    "        url = f\"https://www.atlasobscura.com/places?page={page}&sort=likes_count\"\n",
    "        raw = rq.get(url,headers=headers)\n",
    "        if raw.status_code != 200:\n",
    "            print(\"Sleeping\")\n",
    "            time.sleep(120)\n",
    "            raw = rq.get(url,headers=headers)\n",
    "        \n",
    "        soup = bs.BeautifulSoup(raw.content)\n",
    "        \n",
    "        for d in soup.find_all(\"a\",attrs={'data-place-id':re.compile(r\"\\d+\")}):\n",
    "            cities_url.append(d[\"href\"])\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(page)\n",
    "        print(e)\n",
    "        print(raw.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df76c741-d651-48b8-8ad1-c09a655d47fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cities_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f908991a-7829-42e4-b32e-160d421393e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"links.txt\",\"w\") as f:\n",
    "    for link in cities_url:\n",
    "        complete_url = \"https://www.atlasobscura.com\"+link+\"\\n\"\n",
    "        f.write(complete_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8808f76d-4f6b-4b14-9c21-63bc957d1436",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://www.atlasobscura.com/places?page=2&sort=likes_count\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "138f6d28-ac5a-4d24-955a-744db0a5c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = rq.get(url)\n",
    "soup = bs.BeautifulSoup(raw.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc056e8b-dda9-4b92-812e-4427a2b3070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pretty.txt\",\"w\") as f:\n",
    "    f.write(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d02dd84-9ec0-4251-aa9e-fca49ea7abc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Downloading the html files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3077aa09-401d-4432-9215-c02433152aa8",
   "metadata": {},
   "source": [
    "_(nota per voi) il modulo qua sotto serve per generare degli headers random_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfc05ed-c051-4551-b929-07e8b6ac79d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fake-useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08956134-469a-4d76-b707-2d717e302d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent()\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61561afe-0f7b-4b0f-8307-3541eb670a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of fake headers\n",
    "headers = [ua.random for _ in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e01a60bc-6ca6-4730-b36c-12208acd72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"links.txt\",\"r\") as f:\n",
    "    links = list(map(lambda x: x.rstrip(\"\\n\"), f.readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bb89a4-9c3a-4942-97ea-67163bfd57ec",
   "metadata": {},
   "source": [
    "_salva tutti i file nella cartella \"download\", va modificato quel parametro per mettergli le pagine_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4730c6-a6d6-42cd-8192-b54b0ea49eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_html_downloader(links:list,directory=\"downloads\"):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \"\"\"\n",
    "    Parallelize html downloading by the means of multithreading\n",
    "    \"\"\"\n",
    "    def downloader(url:str, directory=\"downloads\"):\n",
    "        try:\n",
    "            raw = rq.get(url, headers={'User-Agent':random.choice(headers)})   # pick a random user agent for the request\n",
    "            while raw.status_code != 200:\n",
    "                #print(f\"Key error: {raw.status_code}. Sleeping 180s...\")    # wait 180 seconds before doing another get (too many requests)\n",
    "                time.sleep(180)\n",
    "                raw = rq.get(url, headers={'User-Agent':random.choice(headers)})\n",
    "\n",
    "            with open(f\"{directory}/{url.split('/')[-1]}.html\",\"w\") as f:    # save the file.html in the folder\n",
    "                f.write(raw.text) \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        executor.map(downloader, links)    # parallelize the downloader function over list of links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4315a395-6555-408d-a4df-6276e9e80838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 7.84 s, total: 1min 45s\n",
      "Wall time: 1h 56min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parallel_html_downloader(links)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
